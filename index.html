<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8" />
  <title>Speech ‚Üí GPT-4o mini demo + Batch polish</title>

  <!-- Azure Speech SDK -->
  <script src="https://aka.ms/csspeech/jsbrowserpackageraw"></script>
  <!-- Secrets live in settings.js -->
  <script src="settings.js"></script>

  <style>
    body   {font-family:sans-serif;max-width:850px;margin:40px auto}
    button {padding:10px 20px;font-size:1rem;margin:0 8px 12px 0}
    .pane  {white-space:pre-wrap;border:1px solid #ccc;padding:1rem;height:260px;overflow:auto;border-radius:6px}
    #output{background:#f5faff}
    #answer{background:#fffaf5}
    h2     {margin-top:24px;font-size:1.1rem}
    #usage {font-size:0.9rem;color:#555;margin-top:6px}
  </style>
</head>
<body>
  <h1>üé§ Live transcription ‚Üí GPT-4o mini</h1>
  <div>
    <button id="startBtn">Start recording</button>
    <button id="stopBtn"  disabled>Stop recording</button>
    <button id="batchBtn" disabled>Improve with Batch</button>
    <button id="askBtn"   disabled>Ask GPT-4o mini</button>
  </div>

  <h2>Transcript</h2>
  <div id="output" class="pane"></div>

  <h2>GPT-4o mini answer</h2>
  <div id="answer" class="pane"></div>
  <div id="usage"></div>

  <script type="module">
    import OpenAI from "https://cdn.jsdelivr.net/npm/openai@4.26.0/+esm";

    /* -------------------------------------------------------------- */
    /* 1.  Secrets                                                    */
    /* -------------------------------------------------------------- */
    const {
      speechKey, speechRegion,
      openaiKey, openaiBase, deployment, apiVersion,
      blobSasUrl
    } = window.APP_SETTINGS ?? {};

    if (!speechKey || !speechRegion || !openaiKey || !openaiBase ||
        !deployment || !apiVersion || !blobSasUrl) {
      alert("‚ö†Ô∏è  One or more settings are missing in settings.js ‚Äî fill them in and reload.");
    }

    /* -------------------------------------------------------------- */
    /* 2.  DOM helpers                                                */
    /* -------------------------------------------------------------- */
    const $   = id => document.getElementById(id);
    const out = $("output"), ans = $("answer"), usage = $("usage");
    const [startBtn, stopBtn, batchBtn, askBtn] =
          ["startBtn","stopBtn","batchBtn","askBtn"].map($);
    const append = (el, txt) => { el.textContent += txt; el.scrollTop = el.scrollHeight; };

    /* -------------------------------------------------------------- */
    /* 3.  Speech-to-text live                                        */
    /* -------------------------------------------------------------- */
    const speechCfg = SpeechSDK.SpeechConfig.fromSubscription(speechKey, speechRegion);
    speechCfg.speechRecognitionLanguage = "en-US";
    speechCfg.setProperty(
      SpeechSDK.PropertyId.SpeechServiceResponse_DiarizationEnabled, "true"
    );
    const micAudio   = SpeechSDK.AudioConfig.fromDefaultMicrophoneInput();
    const transcriber = new SpeechSDK.ConversationTranscriber(speechCfg, micAudio);

    const transcriptLines = [];
    transcriber.transcribed = (_, e) => {
      const name = `Speaker ${e.result.speakerId}`;
      const line = `${name}: ${e.result.text}\n`;
      transcriptLines.push(line);
      append(out, line);
      askBtn.disabled   = false;
      batchBtn.disabled = false;
    };

    /* -------------------------------------------------------------- */
    /* 4.  MediaRecorder                                              */
    /* -------------------------------------------------------------- */
    let mediaRec; let chunks = [];
    async function startRecording() {
      chunks = [];
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      mediaRec = new MediaRecorder(stream, { mimeType: "audio/webm" });
      mediaRec.ondataavailable = e => chunks.push(e.data);
      mediaRec.start();
    }
    function stopRecording() {
      return new Promise(res => {
        mediaRec.onstop = () => res(new Blob(chunks, { type: "audio/webm" }));
        mediaRec.stop();
      });
    }

    /* -------------------------------------------------------------- */
    /* 5.  Upload blob                                                */
    /* -------------------------------------------------------------- */
    async function uploadToBlob(blob) {
      const i   = blobSasUrl.indexOf("?");
      const root= blobSasUrl.substring(0, i);   // https://.../audio
      const sas = blobSasUrl.substring(i);      // ?sv=...
      const file = `meeting-${Date.now()}.webm`;
      const url  = `${root}/${file}${sas}`;

      const r = await fetch(url, {
        method: "PUT",
        headers: { "x-ms-blob-type": "BlockBlob" },
        body: blob
      });
      if (!r.ok) throw new Error("Blob PUT failed: " + r.status);
      return url;                               // read+write SAS
    }

    /* -------------------------------------------------------------- */
    /* 6.  Batch STT helpers                                          */
    /* -------------------------------------------------------------- */
    const batchEndpoint =
      `https://${speechRegion}.api.cognitive.microsoft.com/speechtotext/v3.1/transcriptions`;

    async function createBatchJob(fileUrl) {
      const body = {
        displayName: `Meeting ${new Date().toISOString()}`,
        contentUrls: [fileUrl],
        locale:      "en-US",
        properties:  { diarizationEnabled: true, punctuationMode: "DictatedAndAutomatic" }
      };
      const r = await fetch(batchEndpoint, {
        method: "POST",
        headers: { "Ocp-Apim-Subscription-Key": speechKey,
                   "Content-Type": "application/json" },
        body: JSON.stringify(body)
      });
      if (!r.ok) throw new Error(await r.text());
      return r.headers.get("location");
    }

    async function pollJob(jobUrl) {
      while (true) {
        const r = await fetch(jobUrl, {
          headers: { "Ocp-Apim-Subscription-Key": speechKey }
        });
        const j = await r.json();
        if (j.status === "Succeeded") return j;
        if (j.status === "Failed")    throw new Error(JSON.stringify(j, null, 2));
        await new Promise(s => setTimeout(s, 8000));
      }
    }

    function applyBatchTranscript(json) {
      let text = "";
      if (json.results?.transcripts?.length) {
        text = json.results.transcripts.map(t => t.transcript).join("\n");
      } else if (json.combinedRecognizedPhrases?.length) {
        text = json.combinedRecognizedPhrases.map(p => p.display).join("\n");
      } else {
        text = "(No transcript text in Batch JSON)";
      }
      out.textContent = text + "\n(Batch polished)";
      transcriptLines.length = 0;
      transcriptLines.push(...text.split(/\r?\n/).map(l => l + "\n"));
    }

    /* -------------------------------------------------------------- */
    /* 7.  GPT client                                                 */
    /* -------------------------------------------------------------- */
    const openai = new OpenAI({
      apiKey: openaiKey,
      baseURL: `${openaiBase}/openai/deployments/${deployment}`,
      dangerouslyAllowBrowser: true,
      defaultQuery: { "api-version": apiVersion }
    });

    async function askGPT() {
      ans.textContent = ""; usage.textContent = "";
      const prompt = 'TOP INSIGHTS first (max 5 bullets), then per-speaker bullets.\\nUse the speaker name before the colon if present, otherwise "Speaker <n>".';

      const resp = await openai.chat.completions.create({
        model: "",
        messages: [
          { role: "system", content: "You are a concise analyst." },
          { role: "user", content: `${prompt}\n\n-----\n${transcriptLines.join("")}-----` }
        ],
        temperature: 0.3
      });

      ans.textContent = resp.choices[0].message.content.trim();
      if (resp.usage) {
        const { prompt_tokens:p, completion_tokens:c, total_tokens:t } = resp.usage;
        usage.textContent = `Tokens ‚Äî prompt ${p}  completion ${c}  total ${t}`;
      }
    }

    /* -------------------------------------------------------------- */
    /* 8.  Buttons                                                    */
    /* -------------------------------------------------------------- */
    startBtn.onclick = async () => {
      out.textContent = ""; ans.textContent = ""; usage.textContent = "";
      transcriptLines.length = 0; askBtn.disabled = true; batchBtn.disabled = true;
      startBtn.disabled = true;  stopBtn.disabled = false;
      await startRecording();
      transcriber.startTranscribingAsync();
    };

    stopBtn.onclick = async () => {
      transcriber.stopTranscribingAsync();
      window._lastAudioBlob = await stopRecording();
      startBtn.disabled = false; stopBtn.disabled = true;
    };

    batchBtn.onclick = async () => {
      batchBtn.disabled = true;
      append(out, "\n‚è≥ Polishing with Batch STT‚Ä¶\n");
      try {
        const fileUrl   = await uploadToBlob(window._lastAudioBlob);
        const jobUrl    = await createBatchJob(fileUrl);
        const jobResult = await pollJob(jobUrl);

        /* ---------- new file-list logic ---------- */
        const filesResp = await fetch(jobResult.links.files, {
          headers: { "Ocp-Apim-Subscription-Key": speechKey }
        });
        const filesJson = await filesResp.json();
        const txFile    = filesJson.values.find(f => f.kind === "Transcription");
        if (!txFile) throw new Error("No transcription file found in job result");

        const transcriptResp = await fetch(txFile.links.contentUrl);
        const transcriptJson = await transcriptResp.json();
        /* ---------------------------------------- */

        applyBatchTranscript(transcriptJson);
        append(out, "\n‚úÖ Batch transcript applied\n");
        askBtn.disabled = false;
      } catch (err) {
        append(out, "‚ùå Batch error: " + err);
        console.error(err);
        batchBtn.disabled = false;
      }
    };

    askBtn.onclick = askGPT;
  </script>
</body>
</html>
