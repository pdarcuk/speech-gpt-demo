<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>ğŸ¤ Speech â†’ GPTâ€‘4o mini</title>
  <script src="https://aka.ms/csspeech/jsbrowserpackageraw"></script>
  <script src="settings.js"></script>
  <style>
    :root{--bg:#fbfbfb;--fg:#111;--pane:#f1f5ff;--pane2:#fff8f3;--border:#d0d7e2;--accent:#2563eb;--accent-h:#1d4ed8}
    @media(prefers-color-scheme:dark){:root{--bg:#0f1522;--fg:#f5f7fa;--pane:#1c2436;--pane2:#2a1e14;--border:#2b3448;--accent:#3b82f6;--accent-h:#60a5fa}}
    *,*::before,*::after{box-sizing:border-box;margin:0;padding:0}
    body{font-family:system-ui,-apple-system,Segoe UI,Roboto,sans-serif;background:var(--bg);color:var(--fg);max-width:1000px;margin:40px auto;padding:0 1rem}
    h1{font-size:1.6rem;font-weight:600;margin:0 0 1rem}
    h2{font-size:1.05rem;font-weight:600;margin:.9rem 0 .4rem}
    button{padding:.6rem 1.1rem;border:0;border-radius:.75rem;font-size:.9rem;background:var(--accent);color:#fff;cursor:pointer;transition:.2s}
    button:hover:not(:disabled){background:var(--accent-h)}button:disabled{opacity:.4;cursor:not-allowed}
    .pane{background:var(--pane);white-space:pre-wrap;border:1px solid var(--border);border-radius:1rem;padding:1rem;height:18rem;overflow:auto}
    #batchOutput{background:var(--pane2)}#answer{background:var(--pane2)}#usage{font-size:.85rem;opacity:.7;margin-top:.4rem}
    .pane::-webkit-scrollbar{width:6px}.pane::-webkit-scrollbar-thumb{background:var(--border);border-radius:3px}
    .grid{display:flex;gap:1rem;flex-wrap:wrap}.grid>div{flex:1 1 300px;min-width:250px}
  </style>
</head>
<body>
  <h1>ğŸ¤ Live Transcription â†’ GPTâ€‘4o mini</h1>

  <h2>Live transcript</h2>
  <button id="startBtn">Start recording</button>
  <button id="stopBtn" disabled>Stop recording</button>
  <div id="liveOutput" class="pane" style="margin-top:.6rem"></div>

  <h2 style="margin-top:1.4rem">Batch transcript</h2>
  <button id="batchBtn" disabled>Improve with Batch</button>
  <div id="batchOutput" class="pane" style="margin-top:.6rem"></div>

  <h2 style="margin-top:1.4rem">GPTâ€‘4o mini answer</h2>
  <label style="display:inline-flex;align-items:center;gap:.4rem;margin-bottom:.4rem">
    <input type="checkbox" id="appendCheck"/>
    Append AIâ€‘cleaned transcript
  </label>
  <button id="askBtn" disabled>Ask GPTâ€‘4o mini</button>
  <div id="answer" class="pane" style="margin-top:.6rem"></div>
  <div id="usage"></div>

  <script type="module">
    import OpenAI from "https://cdn.jsdelivr.net/npm/openai@4.26.0/+esm";
    const {speechKey,speechRegion,openaiKey,openaiBase,deployment,apiVersion,blobSasUrl}=window.APP_SETTINGS??{};
    if(!speechKey||!speechRegion||!openaiKey||!openaiBase||!deployment||!apiVersion||!blobSasUrl){alert("Missing settings");}
    const $=id=>document.getElementById(id);
    const liveEl=$("liveOutput"),batchEl=$("batchOutput"),ansEl=$("answer"),usageEl=$("usage");
    const [startBtn,stopBtn,batchBtn,askBtn] =["startBtn","stopBtn","batchBtn","askBtn"].map($);
    const append=(el,t)=>{el.textContent+=t;el.scrollTop=el.scrollHeight;};

    /* Speech SDK */
    const cfg=SpeechSDK.SpeechConfig.fromSubscription(speechKey,speechRegion);
    cfg.speechRecognitionLanguage="en-US";
    cfg.setProperty(SpeechSDK.PropertyId.SpeechServiceResponse_DiarizationEnabled,"true");
    const mic=SpeechSDK.AudioConfig.fromDefaultMicrophoneInput();
    const stt=new SpeechSDK.ConversationTranscriber(cfg,mic);
    const liveLines = [];
const batchLines = [];
    stt.transcribed = (_, e) => {
      const line = `Speaker ${e.result.speakerId}: ${e.result.text}
`;
      liveLines.push(line);
      append(liveEl, line);
      askBtn.disabled = false;
      batchBtn.disabled = false;
    };};

    /* recording */
    let rec;let chunks=[];async function startRec(){chunks=[];const s=await navigator.mediaDevices.getUserMedia({audio:true});rec=new MediaRecorder(s,{mimeType:"audio/webm"});rec.ondataavailable=e=>chunks.push(e.data);rec.start();}
    function stopRec(){return new Promise(r=>{rec.onstop=()=>r(new Blob(chunks,{type:"audio/webm"}));rec.stop();});}

    /* upload */
    async function up(blob){const i=blobSasUrl.indexOf("?");const root=blobSasUrl.slice(0,i);const sas=blobSasUrl.slice(i);const name=`meeting-${Date.now()}.webm`;const url=`${root}/${name}${sas}`;const res=await fetch(url,{method:"PUT",headers:{"x-ms-blob-type":"BlockBlob"},body:blob});if(!res.ok)throw new Error(res.status);return url;}

    /* batch helpers */
    const ep=`https://${speechRegion}.api.cognitive.microsoft.com/speechtotext/v3.1/transcriptions`;
    async function createJob(u){const body={displayName:`Meeting ${new Date().toISOString()}`,contentUrls:[u],locale:"en-US",properties:{diarizationEnabled:true,punctuationMode:"DictatedAndAutomatic"}};const r=await fetch(ep,{method:"POST",headers:{"Ocp-Apim-Subscription-Key":speechKey,"Content-Type":"application/json"},body:JSON.stringify(body)});if(!r.ok)throw new Error(await r.text());return r.headers.get("location");}
    async function poll(j){while(true){const r=await fetch(j,{headers:{"Ocp-Apim-Subscription-Key":speechKey}});const d=await r.json();if(d.status==="Succeeded")return d;if(d.status==="Failed")throw new Error(JSON.stringify(d));await new Promise(s=>setTimeout(s,8000));}}
    function showBatch(js){
      let text="";
      if(js.results?.transcripts?.length){text=js.results.transcripts.map(t=>t.transcript).join("
");}
      else if(js.combinedRecognizedPhrases?.length){
        text=js.combinedRecognizedPhrases.sort((a,b)=>a.offset-b.offset)
          .map(p=>`Speaker ${p.speaker??p.channel??0}: ${p.display}`).join("
");
      }
      batchEl.textContent=text+"
(Batch polished)";
      batchLines.length=0;
      batchLines.push(...text.split(/
?
/).map(l=>l+"
"));
    }else if(js.combinedRecognizedPhrases?.length){text=js.combinedRecognizedPhrases.sort((a,b)=>a.offset-b.offset).map(p=>`Speaker ${p.speaker??p.channel??0}: ${p.display}`).join("\n");}batchEl.textContent=text+"\n(Batch polished)";lines.length=0;lines.push(...text.split(/\r?\n/).map(l=>l+"\n"));}

    /* GPT */
    const oa=new OpenAI({apiKey:openaiKey,baseURL:`${openaiBase}/openai/deployments/${deployment}`,dangerouslyAllowBrowser:true,defaultQuery:{"api-version":apiVersion}});
    async function ask(){
      ansEl.textContent="";usageEl.textContent="";
      const includeClean=$("appendCheck").checked;
      const topPrompt=`TOP 5 insights from the meeting. Then provide insights per speaker.`;
      const cleanedInstr = includeClean ? "After that, append the AIâ€‘cleaned, speakerâ€‘labelled full transcript under the heading '--- AI-Cleaned Transcript ---'." : "";
      const userContent = `${topPrompt}
${cleanedInstr}

----- LIVE TRANSCRIPT -----
${liveLines.join("")}
----- BATCH TRANSCRIPT -----
${batchLines.join("")}
-----`;
      const r=await oa.chat.completions.create({model:"",temperature:0.3,messages:[
        {role:"system",content:"You are a concise analyst."},
        {role:"user",content:userContent}
      ]});
      ansEl.textContent=r.choices[0].message.content.trim();
      if(r.usage){const{prompt_tokens:p,completion_tokens:c,total_tokens:t}=r.usage;usageEl.textContent=`Tokens â€” prompt ${p}  completion ${c}  total ${t}`;}
    }\n\nAfter the insights, output the cleaned speaker-labelled transcript under a heading '--- AI-Cleaned Transcript ---'.\n\n-----\n${lines.join("")}-----`:`${base}\n\n-----\n${lines.join("")}-----`;const r=await oa.chat.completions.create({model:"",messages:[{role:"system",content:"You are a concise analyst."},{role:"user",content:user}],temperature:0.3});ansEl.textContent=r.choices[0].message.content.trim();if(r.usage){const{prompt_tokens:p,completion_tokens:c,total_tokens:t}=r.usage;usageEl.textContent=`Tokens â€” prompt ${p}  completion ${c}  total ${t}`;}}

    /* buttons */
    startBtn.onclick=async()=>{liveEl.textContent=batchEl.textContent=ansEl.textContent="";usageEl.textContent="";lines.length=0;askBtn.disabled=batchBtn.disabled=true;startBtn.disabled=true;stopBtn.disabled=false;await startRec();stt.startTranscribingAsync();};
    stopBtn.onclick=async()=>{stt.stopTranscribingAsync();window._aud=await stopRec();startBtn.disabled=false;stopBtn.disabled=true;};
    batchBtn.onclick=async()=>{batchBtn.disabled=true;append(batchEl,"\nâ³ Polishing with Batch STTâ€¦\n");try{const u=await up(window._aud);const j=await createJob(u);const res=await poll(j);const fr=await fetch(res.links.files,{headers:{"Ocp-Apim-Subscription-Key":speechKey}});const fj=await fr.json();const txf=fj.values.find(f=>f.kind==="Transcription");if(!txf)throw new Error("No tx file");const tj=await(await fetch(txf.links.contentUrl)).json();showBatch(tj);append(batchEl,"\nâœ… Batch transcript applied\n");askBtn.disabled=false;}catch(e){append(batchEl,"âŒ Batch error: "+e);console.error(e);batchBtn.disabled=false;}};
    askBtn.onclick=ask;
  </script>
</body>
</html>

